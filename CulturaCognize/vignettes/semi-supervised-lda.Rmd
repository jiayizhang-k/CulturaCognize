---
title: "CulturaCognize Vignette: Semi-Supervised LDA on Film Reviews"
author: "Jiayi Zhang"
date: "2025-06-01"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{CulturaCognize: Semi-Supervised LDA on Film Reviews}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# CulturaCognize: Semi-Supervised LDA with Visualization

This vignette walks through a semi-supervised topic modeling workflow for Chinese-language film reviews. It uses LDA with human-coded seed words, offers document similarity visualization via t-SNE, and presents interactive topic exploration through LDAvis.

**Note**: Customized stopwords and dictionary design are examples from our work on *Farewell My Concubine* (Jiayi Zhang and Chandler Rosenberger), who use this pipeline for their work on film reviews using Douban comments. The examples here are intended as illustrative guides for general use.

## Load Required Libraries
```r
library(quanteda)
library(quanteda.textmodels)
library(topicmodels)
library(textmineR)
library(LDAvis)
library(tidyverse)
library(Rtsne)
library(rsconnect)
library(shiny)
library(plotly)
```

## Data Cleaning and Tokenization
```r
corpus_raw <- read_csv("reviews.csv")
corpus_text <- corpus_raw$content

corpus_tokens <- tokens(corpus_text, remove_punct = TRUE, remove_numbers = TRUE)
corpus_tokens <- tokens_remove(corpus_tokens, pattern = stopwords("zh", source = "marimo"))

custom_stopwords <- c("è¶è¡£","éœ¸çŽ‹", "ä¸€ä¸ª", "è‡ªå·±", "è™žå§¬", "ç”µå½±", "å°è±†", "æ²¡æœ‰", "æ—¶å€™", "å°±æ˜¯", "æœ€åŽ", "æœ‰ç”¨", "ä»–ä»¬")

corpus_tokens <- tokens_remove(corpus_tokens, pattern = custom_stopwords)
dfm <- dfm(corpus_tokens)
dfm <- dfm_trim(dfm, min_termfreq = 5, min_docfreq = 3)
```

## Exploratory Visualization via t-SNE (Term-Level)

To assist the seed design process, we first visualize the top 80 terms by **frequency** and **TF-IDF** using 2D t-SNE and cluster them into five groups each. The plot shows term positions and cluster colors interactively.

```r
# Frequency-based term t-SNE
term_matrix_freq <- t(as.matrix(dfm))
top_terms_freq <- names(sort(rowSums(term_matrix_freq), decreasing = TRUE))[1:80]
term_matrix_top_freq <- term_matrix_freq[top_terms_freq, ]
term_matrix_top_freq <- term_matrix_top_freq[!duplicated(term_matrix_top_freq), ]
tsne_freq <- Rtsne(term_matrix_top_freq, dims = 2, perplexity = 20)
term_df_freq <- as.data.frame(tsne_freq$Y)
colnames(term_df_freq) <- c("Dim1", "Dim2")
term_df_freq$Term <- rownames(term_matrix_top_freq)
term_df_freq$Cluster <- as.factor(kmeans(term_df_freq[,1:2], centers = 5)$cluster)

plot_freq <- plot_ly(term_df_freq, x = ~Dim1, y = ~Dim2, type = 'scatter', mode = 'markers+text',
                     text = ~Term, color = ~Cluster, colors = "Set1",
                     textposition = "top center", marker = list(size = 8)) %>%
  layout(title = "t-SNE: Top 80 Terms by Frequency")

# TF-IDF-based term t-SNE
tfidf_matrix <- as.matrix(t(dfm_tfidf(dfm)))
top_terms_tfidf <- names(sort(rowMeans(tfidf_matrix), decreasing = TRUE))[1:80]
term_matrix_top_tfidf <- tfidf_matrix[top_terms_tfidf, ]
term_matrix_top_tfidf <- term_matrix_top_tfidf[!duplicated(term_matrix_top_tfidf), ]
tsne_tfidf <- Rtsne(term_matrix_top_tfidf, dims = 2, perplexity = 20)
term_df_tfidf <- as.data.frame(tsne_tfidf$Y)
colnames(term_df_tfidf) <- c("Dim1", "Dim2")
term_df_tfidf$Term <- rownames(term_matrix_top_tfidf)
term_df_tfidf$Cluster <- as.factor(kmeans(term_df_tfidf[,1:2], centers = 5)$cluster)

plot_tfidf <- plot_ly(term_df_tfidf, x = ~Dim1, y = ~Dim2, type = 'scatter', mode = 'markers+text',
                      text = ~Term, color = ~Cluster, colors = "Set2",
                      textposition = "top center", marker = list(size = 8)) %>%
  layout(title = "t-SNE: Top 80 Terms by TF-IDF")

subplot(plot_freq, plot_tfidf, nrows = 1, margin = 0.05) %>%
  layout(title = "Term-Level t-SNE: Frequency vs. TF-IDF (w/ Labels & Clusters)")
```

## Seed Design with Human Input
```r
seed_topics <- dictionary(list(
  Anomie = c('æ‚²å‰§','ç»æœ›','åŠ¨è¡','æ— æƒ…','å¤±åŽ»','ç—›è‹¦','æ‚²å“€','ç–¯ç‹‚','é»‘æš—','æŒ£æ‰Ž','å®³æ€•','æ··ä¹±','æŠ˜ç£¨','æš´åŠ›','æ‚²æƒ¨','å¯æ‚²','æ²‰é‡','æ®‹å¿','æ‚²ä¼¤','è‹¦éš¾','å´©æºƒ','æ®‹é…·','è‰°è‹¦','è¾›è‹¦'),
  Fatalism = c('å‘½è¿','æ³¨å®š','æ­»äº†','çªç„¶','æˆå°±','æ­»äº¡','æ­»åŽ»','å‡¡äºº','ä¹±ä¸–','æ¯ç­','å®¿å‘½','å¤©å‘½', 'æ— åŠ›','å‘½è‹¦','è®¤å‘½'),
  Powerlessness= c('å¯æƒœ','ä¸æ„¿','éš¾ä»¥','æ™®é€š','å¦¥å','å¹³å‡¡','æ‰¿å—','å±ˆæœ','éšå¿','ç‰ºç‰²','å¯æ€œ','åŽ‹æŠ‘', 'å­¤ç‹¬','æ— å¥ˆ','æ”¾å¼ƒ'),
  Integrity = c('äººæ€§','äººå¿ƒ','äººæ ¼','æŠ›å¼ƒ','æ‰­æ›²','å‡ºå–','è½¬å˜','èƒŒå›','æ­å‘','æ‰¹æ–—','è‡ªä¿','å…­äº²', 'ä¸è®¤'),
...
))
```

## Semi-Supervised LDA using `textmodel_seededlda`
```r
set.seed(2025)
dfm_sslda <- dfm_weight(dfm, scheme = "count")
model <- textmodel_seededlda(dfm_sslda, seed_topics, residual = 3, 
                                auto_iter = FALSE,
                                max_iter = 2000,
                                verbose = TRUE )
```


## Coherence Evaluation
```r
# Optional: Use other metrics or visualization packages here if desired
```

## LDAvis Output
```r
json_lda <- createJSON(
  phi = model$phi, 
  theta = model$theta, 
  doc.length = rowSums(dfm_sslda), 
  vocab = colnames(dfm_sslda), 
  term.frequency = colSums(dfm_sslda)
)
serVis(json_lda)
write(json_lda, file = "lda.json")
serVis(json_lda, out.dir = "LDAvis_output", open.browser = FALSE)
```

## Deploying to Shiny
```r
ui <- shinyUI(
  fluidPage(
    h1('How we make sense of the past?'),
    p('An RShiny page for LDAvis, by Jiayi Zhang'),
    visOutput('myChart')
  )
)

server <- shinyServer(function(input, output, session){
  output$myChart <- renderVis({
     readChar("lda.json", file.info("lda.json")$size)
  })
})

shinyApp(ui = ui, server = server)
```

## Live Demo

You can explore the interactive topic model results for *Farewell My Concubine* directly here:

ðŸ‘‰ **[LDAvis Shiny App â€“ Farewell My Concubine](https://jiayizhangg.shinyapps.io/farewell/#topic=2&lambda=1&term=)**

This visualization presents the output from our semi-supervised LDA model using human-coded seed words and is powered by LDAvis on RShiny.

---

This pipeline illustrates how interpretive human coding can complement statistical modeling for richer insights into cultural reception and memory through film discourse.
